{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import DihedralAdherence\n",
    "from lib import PDBMineQuery, MultiWindowQuery\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, ConcatDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from lib.constants import AMINO_ACID_MAP, AMINO_ACID_MAP_INV\n",
    "from lib.across_window_utils import (\n",
    "    get_phi_psi_dist_window, get_afs_window, get_xrays_window, get_cluster_medoid, find_clusters,\n",
    "    precompute_dists, filter_precomputed_dists, \n",
    ")\n",
    "from collections import defaultdict\n",
    "PDBMINE_URL = os.getenv(\"PDBMINE_URL\")\n",
    "PROJECT_DIR = 'ml_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import ConnectionPatch\n",
    "\n",
    "def plot(q, seq_ctxt, xrays, afs, clusters, phi_psi_dist, precomputed_dists):\n",
    "    n_cluster_plot = 10\n",
    "    n_clusters = len(np.unique(clusters))\n",
    "    xrays = xrays.reshape(2, -1)\n",
    "    afs = afs.reshape(2, -1)\n",
    "    print(pd.Series(clusters).value_counts())\n",
    "\n",
    "    cluster_points = phi_psi_dist.groupby(clusters).count().sort_values('phi_0', ascending=False).index.values\n",
    "    clusters_plot = cluster_points[:n_cluster_plot]\n",
    "    medoids = []\n",
    "    for cluster in cluster_points:\n",
    "        medoid = get_cluster_medoid(phi_psi_dist, precomputed_dists, clusters, cluster)\n",
    "        medoids.append(medoid)\n",
    "    medoids = np.array(medoids)\n",
    "\n",
    "    colors = sns.color_palette('Dark2', n_clusters)\n",
    "    fig, axes = plt.subplots(len(clusters_plot), q.winsize, figsize=(16, min(n_cluster_plot, len(clusters_plot))*4), sharey=True, sharex=True)\n",
    "    if axes.ndim == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    for i,axrow in enumerate(axes):\n",
    "        for j, ax in enumerate(axrow):\n",
    "            cluster_dist = phi_psi_dist[clusters == clusters_plot[i]]\n",
    "\n",
    "            sns.scatterplot(data=phi_psi_dist[clusters != clusters_plot[i]], x=f'phi_{j}', y=f'psi_{j}', ax=ax, label='Other Clusters', color='tab:blue', alpha=0.5)\n",
    "            sns.scatterplot(data=cluster_dist, x=f'phi_{j}', y=f'psi_{j}', ax=ax, label=f'Cluster {clusters_plot[i]}', color=colors[i])\n",
    "            ax.scatter(xrays[0,j], xrays[1,j], color='tab:red', marker='X', label='X-ray', zorder=1000)\n",
    "            ax.scatter(afs[0,j], afs[1,j], color='tab:orange', marker='X', label='AF', zorder=1000)\n",
    "            # ax.scatter(pred[0,j], pred[1,j], color='tab:orange', marker='X', label=pred_id, zorder=1000)\n",
    "            ax.scatter(medoids[i].reshape(2,-1)[0,j], medoids[i].reshape(2,-1)[1,j], color='black', marker='X', label='Cluster Centroid', zorder=1000)\n",
    "\n",
    "            def add_conn(xyA, xyB, color, lw, **kwargs):\n",
    "                con = ConnectionPatch(\n",
    "                    xyA=xyA, \n",
    "                    xyB=xyB, \n",
    "                    coordsA=\"data\", coordsB=\"data\", \n",
    "                    axesA=axrow[j], axesB=axrow[j+1], \n",
    "                    color=color, lw=lw, linestyle='--', alpha=0.5, **kwargs\n",
    "                )\n",
    "                fig.add_artist(con)\n",
    "            if j < q.winsize - 1:\n",
    "                # TODO draw lines for 50 points closest to centroid\n",
    "                for k, row in cluster_dist.sample(min(cluster_dist.shape[0], 50)).iterrows():\n",
    "                    add_conn((row[f'phi_{j}'], row[f'psi_{j}']), (row[f'phi_{j+1}'], row[f'psi_{j+1}']), colors[i], 1)\n",
    "                add_conn((xrays[0,j], xrays[1,j]), (xrays[0,j+1], xrays[1,j+1]), 'tab:red', 5, zorder=100)\n",
    "                add_conn((afs[0,j], afs[1,j]), (afs[0,j+1], afs[1,j+1]), 'tab:orange', 5, zorder=100)\n",
    "                # add_conn((pred[0,j], pred[1,j]), (pred[0,j+1], pred[1,j+1]), 'tab:orange', 5, zorder=100)\n",
    "                add_conn((medoids[i].reshape(2,-1)[0,j], medoids[i].reshape(2,-1)[1,j]), (medoids[i].reshape(2,-1)[0,j+1], medoids[i].reshape(2,-1)[1,j+1]), 'black', 5, zorder=100)\n",
    "\n",
    "            ax.set_xlim(-180, 180)\n",
    "            ax.set_ylim(-180, 180)\n",
    "            ax.set_xlabel('')\n",
    "            if j == q.winsize - 1:\n",
    "                ax.legend()\n",
    "            else:\n",
    "                ax.legend().remove()\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f'Cluster {clusters_plot[i]} [{cluster_dist.shape[0]}]')\n",
    "    fig.supxlabel('Phi')\n",
    "    fig.supylabel('Psi')\n",
    "    # fig.suptitle(\n",
    "    #     # f'Clustered Phi/Psi Distributions for {seq_ctxt} in protein {da.casp_protein_id}: N={n_points} Silhouette Score: {sil_score:.2f}, X-ray Score [Cluster {nearest_cluster}]: {xray_sil:.2f}, Prediction Score [Cluster {nearest_cluster_pred}]: {pred_sil:.2f}', \n",
    "    #     f'Clustered Phi/Psi Distributions for {seq_ctxt} in protein {da.casp_protein_id}: N={n_points} ({n_unassigned} unassigned) Silhouette Score: {sil_score:.2f}, X-ray Score [Cluster {nearest_cluster}]: {xray_maha:.2f}', \n",
    "    #     y=1.01\n",
    "    # )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5NUP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "pdb_codes = json.load(open('proteins.json'))\n",
    "ml_data = [f.name.split('_')[0] for f in Path('ml_data').iterdir()]\n",
    "for pdb_code in pdb_codes[::-1]:\n",
    "    if pdb_code in ml_data:\n",
    "        print(pdb_code)\n",
    "        break\n",
    "pdb_codes.index(pdb_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1FTG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb_codes = [f.name.split('_')[0] for f in Path(PROJECT_DIR).iterdir() if f.is_dir()]\n",
    "ml_samples = [f.stem for f in Path('ml_samples/medoids').iterdir()]\n",
    "for pdb_code in pdb_codes[::-1]:\n",
    "    if pdb_code in ml_samples:\n",
    "        print(pdb_code)\n",
    "        break\n",
    "pdb_codes.index(pdb_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1FTG\n",
      "Results already exist\n",
      "Structure exists: 'pdb/pdb6cj0.ent' \n",
      "UniProt ID: B3G2E1\n",
      "6CJ0\n",
      "(237, 1) 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237it [02:09,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "pdb_codes = [f.name.split('_')[0] for f in Path(PROJECT_DIR).iterdir() if f.is_dir()]\n",
    "winsizes = [4,5,6,7]\n",
    "outdir = Path(f'ml_samples/medoids')\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "X_lens = [15, 5, 3, 2]\n",
    "\n",
    "for id in pdb_codes[593:]:\n",
    "    if (outdir / f'{id}.pt').exists():\n",
    "        print('Skipping', id)\n",
    "        continue\n",
    "    try:\n",
    "        da = MultiWindowQuery(id, winsizes, PDBMINE_URL, PROJECT_DIR)\n",
    "        da.load_results()\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    if da.af_phi_psi is None:\n",
    "        continue\n",
    "    print(id)\n",
    "\n",
    "    center_idx_ctxt = da.queries[-1].get_center_idx_pos()\n",
    "    winsize_ctxt = da.queries[-1].winsize\n",
    "    seqs_for_window = da.seqs[center_idx_ctxt:-(winsize_ctxt - center_idx_ctxt - 1)]\n",
    "    seqs_for_window = pd.DataFrame({'seq_ctxt': seqs_for_window})\n",
    "\n",
    "    seqs = pd.merge(\n",
    "        seqs_for_window,\n",
    "        da.af_phi_psi[['seq_ctxt']], \n",
    "        on='seq_ctxt'\n",
    "    ).rename(columns={'seq_ctxt': 'seq'})\n",
    "    if seqs.shape[0] == 0:\n",
    "        print('No sequences for', id)\n",
    "        continue\n",
    "    print(seqs.shape, seqs.seq.nunique())\n",
    "\n",
    "    x_medoids = defaultdict(list)\n",
    "    x_af = defaultdict(list)\n",
    "    x_res = []\n",
    "    y = []\n",
    "\n",
    "    for i,row in tqdm(seqs.iterrows()):\n",
    "        # Check if alphafold data is complete for largest window size\n",
    "        afs = get_afs_window(da, da.queries[-1], row.seq)\n",
    "        if (afs is None) or (afs.shape[0] != da.queries[-1].winsize*2) or (np.isnan(afs).any()):\n",
    "            # print(f\"AF data for {row.seq} is incomplete\")\n",
    "            continue\n",
    "        # Check if xrays are complete for largest window size\n",
    "        xrays = get_xrays_window(da, da.queries[-1], row.seq)\n",
    "        if xrays.shape[0] != da.queries[-1].winsize*2 or np.isnan(xrays).any():\n",
    "            # print(f\"Xray data for {row.seq} is incomplete\")\n",
    "            continue\n",
    "        for j,q in enumerate(da.queries):\n",
    "            xrays = get_xrays_window(da, q, row.seq)\n",
    "            afs = get_afs_window(da, q, row.seq)\n",
    "            phi_psi_dist = get_phi_psi_dist_window(q, row.seq)\n",
    "            skip = False\n",
    "            # if xrays.shape[0] != q.winsize*2 or np.isnan(xrays).any():\n",
    "                # print(f\"Xray data for {row.seq} is incomplete\")\n",
    "                # skip = True\n",
    "            # if (afs is None) or (afs.shape[0] != q.winsize*2) or (np.isnan(afs).any()):\n",
    "                # print(f\"AF data for {row.seq} is incomplete\")\n",
    "                # skip = True\n",
    "\n",
    "            phi_psi_dist = phi_psi_dist.dropna()\n",
    "            phi_psi_dist = phi_psi_dist[(phi_psi_dist <= 180).all(axis=1)]\n",
    "            \n",
    "            if phi_psi_dist.shape[0] == 0:\n",
    "                # print(f\"No pdbmine data for {row.seq}\")\n",
    "                skip = True\n",
    "            if phi_psi_dist.shape[1] != q.winsize*2:\n",
    "                # print(f\"Phi/Psi data for {row.seq} is incomplete\")\n",
    "                skip = True\n",
    "            if phi_psi_dist.shape[0] > 10000:\n",
    "                phi_psi_dist = phi_psi_dist.sample(10000)\n",
    "            \n",
    "            medoids = np.zeros([X_lens[j], q.winsize*2])\n",
    "\n",
    "            if not skip and phi_psi_dist.shape[0] == 1:\n",
    "                medoids[0] = phi_psi_dist.iloc[0].values\n",
    "            elif not skip and phi_psi_dist.shape[0] > 1:\n",
    "                # Cluster\n",
    "                dists = precompute_dists(phi_psi_dist)\n",
    "                n_clusters, clusters = find_clusters(dists, min_cluster_size=np.min([phi_psi_dist.shape[0], 20]), cluster_selection_epsilon=30)\n",
    "\n",
    "                if n_clusters == 0:\n",
    "                    n_clusters, clusters = find_clusters(dists, min_cluster_size=2, cluster_selection_epsilon=60)\n",
    "                \n",
    "                if n_clusters == 0:\n",
    "                    n_clusters, clusters = find_clusters(dists, min_cluster_size=2, cluster_selection_epsilon=120)\n",
    "                \n",
    "                if n_clusters > 0:\n",
    "                    dists, phi_psi_dist, clusters = filter_precomputed_dists(dists, phi_psi_dist, clusters)\n",
    "                    cluster_counts = pd.Series(clusters).value_counts().sort_values(ascending=False)\n",
    "                    for k,cluster in zip(range(X_lens[j]), cluster_counts.index):\n",
    "                        medoid = get_cluster_medoid(phi_psi_dist, dists, clusters, cluster)\n",
    "                        medoids[k] = medoid\n",
    "\n",
    "            x_medoids[j].append(torch.tensor(medoids, dtype=torch.float32))\n",
    "            x_af[j].append(torch.tensor(afs, dtype=torch.float32))\n",
    "        x_res.append(AMINO_ACID_MAP[row.seq[center_idx_ctxt]])\n",
    "        y.append(torch.tensor(xrays.reshape(2, -1)[:, center_idx_ctxt], dtype=torch.float32))\n",
    "        if torch.isnan(y[-1]).any():\n",
    "            print('Xray data is nan for', row.seq)\n",
    "    if len(y) == 0:\n",
    "        print('No data for', id)\n",
    "        continue\n",
    "    for i in range(len(da.queries)):\n",
    "        x_medoids[i] = torch.stack(x_medoids[i])\n",
    "        x_af[i] = torch.stack(x_af[i])\n",
    "\n",
    "    x_res = F.one_hot(torch.tensor(x_res).to(torch.int64), num_classes=20).float()\n",
    "    y = torch.stack(y)\n",
    "    torch.save((list(x_medoids.values()), (list(x_af.values())), x_res, y), outdir / f'{id}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('ml_samples/medoids/3DE6.pt')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(Path('ml_samples/medoids').iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_medoids, x_af, x_res, y = torch.load('ml_samples/medoids/3DE6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([260, 2, 14])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_medoids[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m in enumerate(x_medoids[1]):\n",
    "    if m.shape[1] != 10:\n",
    "        print(i,m.shape, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, af, xres, y = torch.load(outdir / f'{id}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(n_clusters_all[4]).mean(), np.array(n_clusters_all[4]).std()\n",
    "# np.array(n_clusters_all[7]).mean(), np.array(n_clusters_all[7]).std()\n",
    "average_clusters = {k: np.array(v).mean() for k,v in n_clusters_all.items()}\n",
    "std_clusters = {k: np.array(v).std() for k,v in n_clusters_all.items()}\n",
    "\n",
    "# avg:\n",
    "# 4: 12.675570539419088\n",
    "# 5: 2.2909803921568628\n",
    "# 6: 1.2014057853473912\n",
    "# 7: 1.0849134377576257\n",
    "\n",
    "# std:\n",
    "# 4: 7.717139186664446\n",
    "# 5: 1.4648062017775114\n",
    "# 6: 0.5645546946235267\n",
    "# 7: 0.3251658412701237"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
