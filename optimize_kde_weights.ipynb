{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import DihedralAdherence\n",
    "from lib import PDBMineQuery\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "PDBMINE_URL = os.getenv(\"PDBMINE_URL\")\n",
    "PROJECT_DIR = 'tests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing T1049 ...\n",
      "Results already exist\n",
      "Casp ID: T1049 \tPDB: 6y4f\n",
      "Structure exists: 'pdb/pdb6y4f.ent' \n"
     ]
    }
   ],
   "source": [
    "proteins = ['T1024', 'T1096', 'T1027', 'T1082', 'T1091', 'T1058', 'T1049', 'T1030', 'T1056', 'T1038', 'T1025', 'T1028']\n",
    "\n",
    "da = DihedralAdherence(proteins[6], [4,5,6,7], PDBMINE_URL, PROJECT_DIR)\n",
    "da.load_results()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, id, path):\n",
    "        self.id = id\n",
    "        self.path = path\n",
    "\n",
    "        self.X, self.y, self.xres, self.af = torch.load(self.path / f'{id}.pt')\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.xres[i], self.af[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47572, 25179, 72751)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [4096, 512, 256, 256]\n",
    "path = Path('ml_samples/'+'-'.join([str(l) for l in lengths]))\n",
    "samples = [f.stem for f in path.iterdir()]\n",
    "\n",
    "from lib.retrieve_data import retrieve_target_list\n",
    "ids = ['T1024', 'T1096', 'T1027', 'T1082', 'T1091', 'T1058', 'T1049', 'T1030', 'T1056', 'T1038', 'T1025', 'T1028']\n",
    "targetlist = retrieve_target_list()\n",
    "skip = [targetlist.loc[id, 'pdb_code'].upper() for id in ids]\n",
    "samples = sorted(list(set(samples) - set(skip)))\n",
    "\n",
    "train, test = train_test_split(samples, test_size=0.35, random_state=42)\n",
    "torch.save((train, test), 'ml_data/split.pt')\n",
    "# train, test = to ch.load('ml_data/split.pt')\n",
    "train_dataset = ConcatDataset([ProteinDataset(s, path) for s in train])\n",
    "test_dataset = ConcatDataset([ProteinDataset(s, path) for s in test])\n",
    "trainloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "len(train_dataset), len(test_dataset), len(train_dataset) + len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inverse(torch.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0,2.0])\n",
    "# x2 = torch.tensor([1,2]).unsqueeze(0).T\n",
    "x @ torch.eye(2) @ x.T\n",
    "\n",
    "# torch.tensor([1,2]).pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ (torch.eye(2) * 0.1) @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.pow(2).sum() * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "(2, 10000)\n"
     ]
    }
   ],
   "source": [
    "X,xres,af,y = train_dataset[0]\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "kdews = [1,1,1,1]\n",
    "weights = np.concatenate([np.array([w]*l) for w,l in zip(kdews, lengths)])\n",
    "# weights = weights / weights.sum()\n",
    "# X = X.numpy()\n",
    "# X\n",
    "# plt.plot(weights)\n",
    "\n",
    "# Kernel Density Estimation\n",
    "h = 0.5\n",
    "h_det = torch.det(torch.eye(4) * h)\n",
    "def K(x):\n",
    "    # 2 dimensional standard normal distribution\n",
    "    return torch.exp(-0.5 * x.pow(2).sum() * h) / (2 * np.pi * h_det)\n",
    "def kde(xi):\n",
    "    if xi.ndim == 1:\n",
    "        print(xi.shape)\n",
    "        xi = xi.unsqueeze(1)\n",
    "        print(xi.shape)\n",
    "    likelihood = 0\n",
    "    for w,x in zip(weights,X.T):\n",
    "        likelihood += w * K(x - xi)\n",
    "    return likelihood / weights.sum()\n",
    "kde(torch.tensor([-1.81818182,  1.81818182]))\n",
    "\n",
    "# Find most likely dihedral angles\n",
    "phi_grid, psi_grid = np.meshgrid(np.linspace(-180, 180, 100), np.linspace(-180, 180, 100))\n",
    "grid = np.vstack([phi_grid.ravel(), psi_grid.ravel()])\n",
    "# probs = kde(grid).reshape(phi_grid.shape)\n",
    "# kdepeak = grid[:,probs.argmax()]\n",
    "# kdepeak, probs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.81818182,  1.81818182]), 9.060125326719408e-05)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde = gaussian_kde(X, weights=weights)\n",
    "phi_grid, psi_grid = np.meshgrid(np.linspace(-180, 180, 100), np.linspace(-180, 180, 100))\n",
    "grid = np.vstack([phi_grid.ravel(), psi_grid.ravel()])\n",
    "probs = kde(grid).reshape(phi_grid.shape)\n",
    "kdepeak = grid[:,probs.argmax()]\n",
    "kdepeak, probs.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
