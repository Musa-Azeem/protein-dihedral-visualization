{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import DihedralAdherence\n",
    "from lib import PDBMineQuery\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import json\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, HDBSCAN\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import inv\n",
    "\n",
    "PDBMINE_URL = os.getenv(\"PDBMINE_URL\")\n",
    "PROJECT_DIR = 'casp_da'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing T1053-D1 ...\n",
      "Results already exist\n",
      "Casp ID: T1053-D1 \tPDB: 7m7a\n",
      "Structure exists: 'pdb/pdb7m7a.ent' \n",
      "UniProt ID: Q5ZRA8\n"
     ]
    }
   ],
   "source": [
    "proteins = [\n",
    "  'T1024', 'T1030', 'T1030-D2', 'T1024-D1', 'T1032-D1', 'T1053-D1', 'T1027-D1', 'T1029-D1',\n",
    "  'T1025-D1', 'T1028-D1', 'T1030-D1', 'T1053-D2', 'T1057-D1','T1058-D1', 'T1058-D2'\n",
    "]\n",
    "da = DihedralAdherence(proteins[5], [4,5,6,7], PDBMINE_URL, PROJECT_DIR, kdews=[1,1,1,1], \n",
    "                      mode='full_window', weights_file='ml_runs/best_model-kde_16-32_383.pt', device='cpu')\n",
    "                    #   mode='ml', weights_file='ml_runs/best_model-kde_16-32_383.pt', device='cpu')\n",
    "\n",
    "da.load_results_da()\n",
    "center_idx_ctxt = da.queries[-1].get_center_idx()\n",
    "winsize_ctxt = da.queries[-1].winsize\n",
    "if center_idx_ctxt < 0:\n",
    "    center_idx_ctxt = winsize_ctxt + center_idx_ctxt\n",
    "da.seqs_for_window = da.seqs[center_idx_ctxt:-(winsize_ctxt - center_idx_ctxt - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(x1, x2):\n",
    "    d = np.abs(x1 - x2)\n",
    "    return np.minimum(d, 360-d)\n",
    "\n",
    "def get_phi_psi_dist(q, seq_ctxt):\n",
    "    seq = q.get_subseq(seq_ctxt)\n",
    "    phi_psi_dist = q.results_window[q.results_window.seq == seq]\n",
    "    phi_psi_dist = phi_psi_dist[['match_id', 'window_pos', 'phi', 'psi']].pivot(index='match_id', columns='window_pos', values=['phi', 'psi'])\n",
    "    phi_psi_dist.columns = [f'{c[0]}_{c[1]}' for c in phi_psi_dist.columns.to_flat_index()]\n",
    "    phi_psi_dist = phi_psi_dist.dropna(axis=0)\n",
    "    return phi_psi_dist\n",
    "\n",
    "def get_xrays(ins, q, seq_ctxt, return_df=False):\n",
    "    center_idx = q.get_center_idx_pos()\n",
    "    xray_pos = ins.xray_phi_psi[ins.xray_phi_psi.seq_ctxt == seq_ctxt].pos.iloc[0]\n",
    "    xrays = ins.xray_phi_psi[(ins.xray_phi_psi.pos >= xray_pos-center_idx) & (ins.xray_phi_psi.pos < xray_pos-center_idx+q.winsize)].copy()\n",
    "    xray_point = np.concatenate([xrays['phi'].values, xrays['psi'].values])\n",
    "    if return_df:\n",
    "        return xray_point, xrays\n",
    "    return xray_point\n",
    "\n",
    "def get_afs(ins, q, seq_ctxt, return_df=False):\n",
    "    center_idx = q.get_center_idx_pos()\n",
    "    af_pos = ins.af_phi_psi[ins.af_phi_psi.seq_ctxt == seq_ctxt].pos.iloc[0]\n",
    "    afs = ins.af_phi_psi[(ins.af_phi_psi.pos >= af_pos-center_idx) & (ins.af_phi_psi.pos < af_pos-center_idx+q.winsize)].copy()\n",
    "    af_point = np.concatenate([afs['phi'].values, afs['psi'].values])\n",
    "    if return_df:\n",
    "        return af_point, afs\n",
    "    return af_point\n",
    "\n",
    "def get_preds(ins, q, seq_ctxt):\n",
    "    center_idx = q.get_center_idx_pos()\n",
    "    pred_pos = ins.phi_psi_predictions[ins.phi_psi_predictions.seq_ctxt == seq_ctxt].pos.unique()\n",
    "    if len(pred_pos) == 0:\n",
    "        print(f\"No predictions for {seq_ctxt}\")\n",
    "    if len(pred_pos) > 1:\n",
    "        print(f\"Multiple predictions for {seq_ctxt}\")\n",
    "        raise ValueError\n",
    "    pred_pos = pred_pos[0]\n",
    "    preds = ins.phi_psi_predictions[(ins.phi_psi_predictions.pos >= pred_pos-center_idx) & (ins.phi_psi_predictions.pos < pred_pos-center_idx+q.winsize)].copy()\n",
    "    preds = preds[['protein_id', 'pos', 'phi', 'psi']].pivot(index='protein_id', columns='pos', values=['phi', 'psi'])\n",
    "    preds.columns = [f'{c[0]}_{c[1]-pred_pos+center_idx}' for c in preds.columns.to_flat_index()]\n",
    "    preds = preds.dropna(axis=0)\n",
    "    return preds\n",
    "\n",
    "def calc_xray_score(phi_psi_dist, xrays, q, precomputed_dists):\n",
    "    # Distance to nearest cluster average\n",
    "    d = np.linalg.norm(diff(xrays[np.newaxis,:], phi_psi_dist.iloc[:,:q.winsize*2].values), axis=1)\n",
    "    d = pd.DataFrame({'d': d, 'c': phi_psi_dist.cluster})\n",
    "    nearest_cluster = d.groupby('c').d.mean().idxmin()\n",
    "    cluster_points = phi_psi_dist[phi_psi_dist.cluster == nearest_cluster].iloc[:,:q.winsize*2].values\n",
    "    # cluster_avg = cluster_points.mean(axis=0)\n",
    "    cluster_medoid = get_cluster_medoid(phi_psi_dist, precomputed_dists, nearest_cluster, q)\n",
    "    \n",
    "    xray_dist = np.sqrt((diff(xrays, cluster_medoid)**2).sum())\n",
    "\n",
    "    return xray_dist, nearest_cluster\n",
    "\n",
    "def estimate_icov(q, phi_psi_dist_c, cluster_medoid):\n",
    "    # estimate covariance matrix\n",
    "    cluster_points = phi_psi_dist_c.iloc[:,:q.winsize*2].values\n",
    "    diffs = diff(cluster_points, cluster_medoid)\n",
    "\n",
    "    # cov = []\n",
    "    # for diffi in diffs:\n",
    "    #     diffi = diffi.reshape(-1, 1)\n",
    "    #     cov.append(diffi @ diffi.T)\n",
    "    # cov = np.array(cov).sum(axis=0) / (diffs.shape[0] - 1)\n",
    "    cov = (diffs[...,np.newaxis] @ diffs[:,np.newaxis]).sum(axis=0) / (diffs.shape[0] - 1)\n",
    "    cov = cov + np.eye(cov.shape[0]) * 1e-6 # add small value to diagonal to avoid singular matrix\n",
    "    if np.any(cov <= 0):\n",
    "        print(\"Non-positive covariance matrix\")\n",
    "        return None\n",
    "    if np.any(cov.diagonal() < 1):\n",
    "        print(\"Covariance matrix less than 1\")\n",
    "        return None\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "    if np.any(eigenvalues < 0):\n",
    "        print(\"Negative eigenvalues - non-positive semi-definite covariance matrix\")\n",
    "        return None\n",
    "    icov = inv(cov)\n",
    "    return icov\n",
    "\n",
    "def get_target_cluster(q, phi_psi_dist, point):\n",
    "    d = np.linalg.norm(diff(point[np.newaxis,:], phi_psi_dist.iloc[:,:q.winsize*2].values), axis=1)\n",
    "    d = pd.DataFrame({'d': d, 'c': phi_psi_dist.cluster})\n",
    "    nearest_cluster = d.groupby('c').d.mean().idxmin()\n",
    "    return nearest_cluster\n",
    "\n",
    "def calc_maha_xray(phi_psi_dist, xrays, q, precomputed_dists, af):\n",
    "    target_cluster = get_target_cluster(q, phi_psi_dist, af)\n",
    "    cluster_medoid = get_cluster_medoid(phi_psi_dist, precomputed_dists, target_cluster, q)\n",
    "    icov = estimate_icov(q, phi_psi_dist[phi_psi_dist.cluster == target_cluster], cluster_medoid)\n",
    "    if icov is None:\n",
    "        return None, target_cluster    \n",
    "\n",
    "    # xray_maha_\n",
    "    xray_diff = diff(xrays, cluster_medoid)\n",
    "    xray_maha = np.sqrt(xray_diff @ icov @ xray_diff)\n",
    "\n",
    "    return xray_maha, target_cluster\n",
    "\n",
    "def calc_maha_preds(phi_psi_dist, preds, q, precomputed_dists, af):\n",
    "    target_cluster = get_target_cluster(q, phi_psi_dist, af)\n",
    "    cluster_medoid = get_cluster_medoid(phi_psi_dist, precomputed_dists, target_cluster, q)\n",
    "    icov = estimate_icov(q, phi_psi_dist[phi_psi_dist.cluster == target_cluster], cluster_medoid)\n",
    "    if icov is None:\n",
    "        return None\n",
    "\n",
    "    # Distance from preds to target\n",
    "    preds_diff = diff(preds.iloc[:,:q.winsize*2].values, cluster_medoid)\n",
    "    preds_maha = np.sqrt((preds_diff @ icov @ preds_diff.T).diagonal())\n",
    "    return preds_maha\n",
    "\n",
    "def calc_score(q, preds, phi_psi_dist, intracluster_dists, xrays=None, afs=None):\n",
    "    # Distance to nearest cluster average\n",
    "    d = np.linalg.norm(diff(preds.iloc[:,:q.winsize*2].values[:,np.newaxis], phi_psi_dist.iloc[:,:q.winsize*2].values), axis=2)\n",
    "    average_dists = []\n",
    "    clusters = phi_psi_dist.cluster.unique()\n",
    "    for c in clusters:\n",
    "        average_dists.append(d[:,phi_psi_dist.cluster == c].mean(axis=1))\n",
    "    average_dists = np.array(average_dists).T\n",
    "    min_dists = average_dists.min(axis=1)\n",
    "    nearest_clusters = average_dists.argmin(axis=1)\n",
    "\n",
    "    preds_dist = pd.DataFrame(index=preds.index, columns=['dist'])\n",
    "    preds_dist['dist'] = preds_dist['dist'].astype(float)\n",
    "    for c in clusters:\n",
    "        cluster_points = phi_psi_dist[phi_psi_dist.cluster == c].iloc[:,:q.winsize*2].values\n",
    "        cluster_avg = cluster_points.mean(axis=0) # TODO: use medoid\n",
    "        preds_c = preds[nearest_clusters == c].iloc[:,:q.winsize*2].values\n",
    "        preds_dists_c = np.linalg.norm(diff(preds_c, cluster_avg), axis=1)\n",
    "        preds_dist.loc[nearest_clusters == c, 'dist'] = preds_dists_c\n",
    "\n",
    "    return preds_dist.dist.values\n",
    "\n",
    "# def calc_intra_cluster(phi_psi_dist, precomputed_dists):\n",
    "#     ds = {}\n",
    "#     for c in phi_psi_dist.cluster.unique():\n",
    "#         d = precomputed_dists[phi_psi_dist.cluster == c][:,phi_psi_dist.cluster == c]\n",
    "#         ds[c] = d.sum() / (d.shape[0] * (d.shape[0]-1))\n",
    "#     return ds\n",
    "\n",
    "def get_cluster_medoid(phi_psi_dist, precomputed_dists, c, q):\n",
    "    d = precomputed_dists[phi_psi_dist.cluster == c][:,phi_psi_dist.cluster == c]\n",
    "    return phi_psi_dist[phi_psi_dist.cluster == c].iloc[d.sum(axis=1).argmin(), :q.winsize*2].values\n",
    "\n",
    "def precompute_dists(phi_psi_dist):\n",
    "    def diff(x1, x2):\n",
    "            d = np.abs(x1 - x2)\n",
    "            return np.minimum(d, 360-d)\n",
    "    precomputed_dists = np.linalg.norm(diff(phi_psi_dist.values[:,np.newaxis], phi_psi_dist.values), axis=2)\n",
    "    return precomputed_dists\n",
    "    \n",
    "# def assign_clusters(phi_psi_dist, precomputed_dists, eps=75):\n",
    "#     phi_psi_dist['cluster'] = DBSCAN(eps=eps, min_samples=5, metric='precomputed').fit(precomputed_dists).labels_\n",
    "#     n_clusters = len(phi_psi_dist.cluster.unique())\n",
    "#     return n_clusters\n",
    "\n",
    "def assign_clusters(phi_psi_dist, precomputed_dists):\n",
    "    precomputed_dists = precomputed_dists.copy()\n",
    "    # phi_psi_dist['cluster'] = HDBSCAN(min_cluster_size=20, min_samples=5, metric='precomputed').fit(precomputed_dists).labels_\n",
    "    phi_psi_dist['cluster'] = HDBSCAN(\n",
    "        min_cluster_size=20, \n",
    "        # min_samples=5, \n",
    "        metric='precomputed', \n",
    "        allow_single_cluster=True,\n",
    "        cluster_selection_epsilon=30\n",
    "    ).fit(precomputed_dists).labels_\n",
    "    n_clusters = len(phi_psi_dist.cluster.unique())\n",
    "    return n_clusters - 1\n",
    "\n",
    "def plot(q, phi_psi_dist, xrays=None, c=None):\n",
    "    fig, axes = plt.subplots(1,q.winsize, figsize=(q.winsize*4,5))\n",
    "    if xrays is not None:\n",
    "        xrays = xrays.reshape(2, -1)\n",
    "    phi_psi_dist_points = phi_psi_dist.iloc[:,:q.winsize*2].values.reshape(phi_psi_dist.shape[0], 2, -1)\n",
    "    for i in range(q.winsize):\n",
    "        axes[i].scatter(phi_psi_dist_points[:,0,i], phi_psi_dist_points[:,1,i], marker='.')\n",
    "        if c is not None:\n",
    "            axes[i].scatter(phi_psi_dist_points[phi_psi_dist.cluster==c,0,i], phi_psi_dist_points[phi_psi_dist.cluster==c,1,i], c='orange', zorder=5)\n",
    "        if xrays is not None:\n",
    "            axes[i].scatter(xrays[0,i], xrays[1,i], c='r', marker='X', zorder=10, s=100)\n",
    "        axes[i].set_xlim(-180,180)\n",
    "        axes[i].set_ylim(-180,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDBMineWindow():\n",
    "    def __init__(self, q, seq_ctxt, index):\n",
    "        self.seq_ctxt = seq_ctxt\n",
    "        self.index = index\n",
    "        self.medoids = None\n",
    "        self.q = q\n",
    "        self.find_medoids()\n",
    "    \n",
    "    def find_medoids(self):\n",
    "        phi_psi_dist = get_phi_psi_dist(self.q, self.seq_ctxt)\n",
    "        precomputed_dists = precompute_dists(phi_psi_dist)\n",
    "        n_clusters = assign_clusters(phi_psi_dist, precomputed_dists)\n",
    "        self._medoids = np.array([get_cluster_medoid(\n",
    "            phi_psi_dist, precomputed_dists, c, self.q\n",
    "        ) for c in range(n_clusters) if c != -1])\n",
    "        self.medoids = [Medoid(i, self._medoids) for i in range(len(self._medoids))]\n",
    "    \n",
    "    def extend_and_spawn_threads(self, other, threshold=30):\n",
    "        # Distnace from each medoid of this window to each medoid of other window\n",
    "        range1 = np.concatenate([np.arange(q.winsize-1), np.arange(q.winsize, q.winsize*2-1)])\n",
    "        range2 = np.concatenate([np.arange(1, q.winsize), np.arange(q.winsize+1, q.winsize*2)])\n",
    "        dists = np.linalg.norm(diff(self._medoids[:,np.newaxis,range1], other._medoids[:,range2]), axis=2)\n",
    "\n",
    "        # Extend clusters with close matches\n",
    "        closest = dists.argmin(axis=1)\n",
    "        min_dists = dists.min(axis=1)\n",
    "        for i,medoid in enumerate(self.medoids):\n",
    "            if min_dists[i] < threshold:\n",
    "                # extend thread\n",
    "                if other.medoids[closest[i]].thread is None:\n",
    "                    medoid.thread.length += 1\n",
    "                    other.medoids[closest[i]].thread = medoid.thread\n",
    "                # other medoid already assigned to a thread, merge them\n",
    "                else:\n",
    "                    medoid.thread = other.medoids[closest[i]].thread\n",
    "                    # TODO backtrack and reassign all medoids in this thread to the new thread\n",
    "                other.medoids[closest[i]].assign_thread(medoid.thread)\n",
    "\n",
    "        # Spawn new threads from any medoids in other window that were not matched\n",
    "        for i,medoid in enumerate(other.medoids):\n",
    "            if medoid.thread is None:\n",
    "                # spawn new thread\n",
    "                medoid.thread = Thread()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"PDBMineWindow({self.seq_ctxt}, {self.index})={len(self.medoids)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Medoid():\n",
    "    def __init__(self, index, medoids):\n",
    "        self.index = index # index of this medoid in the window\n",
    "        self.thread = None # pointer to medoid thread this belonds to\n",
    "        self.medoids = medoids # pointer to all medoids of this window\n",
    "    \n",
    "    @property\n",
    "    def medoid(self):\n",
    "        return self.medoids[self.index]\n",
    "    \n",
    "    def assign_thread(self, thread):\n",
    "        self.thread = thread\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Medoid[{self.thread}]({self.medoids[self.index]})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedoidThreads():\n",
    "    def __init__(self, initial_window):\n",
    "        self.window = initial_window # last window of live threads\n",
    "        self.threads = []\n",
    "        for medoid in self.window.medoids:\n",
    "            self.threads.append(Thread())\n",
    "            medoid.assign_thread(self.threads[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thread():\n",
    "    _id = 0\n",
    "    def __init__(self):\n",
    "        # self.medoid = initial_medoid # last medoid of thread\n",
    "        self.length = 1\n",
    "        self.id = Thread._id\n",
    "        self.alive = True\n",
    "        Thread._id += 1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Thread[{self.id}]={self.length}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "for i,seq_ctxt in enumerate(da.seqs_for_window):\n",
    "    window = PDBMineWindow(da.queries[0], seq_ctxt, i)\n",
    "    \n",
    "    # intialize medoid threads\n",
    "    if i == 0:\n",
    "        for medoid in window.medoids:\n",
    "            medoid.assign_thread(Thread())\n",
    "    # Extend existing threads or create new ones\n",
    "    else:\n",
    "        windows[-1].extend_and_spawn_threads(window)\n",
    "\n",
    "    windows.append(window)\n",
    "    # plot(da.queries[0], phi_psi_dist, c=phi_psi_dist.groupby('cluster').size().idxmax())\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Medoid[Thread[71]=1]([-70.4 -81.1 -97.9 -64.1 110.1 -32.8 163.4 -41.6]),\n",
       " Medoid[Thread[72]=2]([-64.8 -65.2 -67.3  56.9 -41.2 -30.9 -13.7  37.6]),\n",
       " Medoid[Thread[73]=1]([ -71.2  -85.8 -143.8 -134.6  127.   -50.8  155.2  126.2]),\n",
       " Medoid[Thread[74]=1]([-62.4 -76.6  67.  -87.  -15.7 -34.3  40.5 148.3]),\n",
       " Medoid[Thread[75]=1]([-72.1 -69.8 -36.9 -58.8 161.3 149.6 -30.6 -48.5]),\n",
       " Medoid[Thread[76]=2]([-67.  -83.2 -67.6 -58.1 -26.3 -12.5 148.1 134.9]),\n",
       " Medoid[Thread[77]=1]([-69.7 -76.1 -66.7 -59.5 -23.9 147.8 176.3 -31.2]),\n",
       " Medoid[Thread[78]=1]([ -87.4 -105.5  -96.7  -54.4   -4.6  144.4  133.6  -41.5]),\n",
       " Medoid[Thread[79]=1]([-137.4  -71.9 -145.  -122.2  153.2  127.7  102.6   -6.1]),\n",
       " Medoid[Thread[80]=1]([-115.9 -148.3  -58.6 -153.6  125.8  161.3  113.2  155. ]),\n",
       " Medoid[Thread[81]=1]([ -92.  -110.6 -157.1  -70.6  117.9  145.6  124.3   -4.9]),\n",
       " Medoid[Thread[82]=2]([-76.6 -64.7 -61.  -65.9 155.6 -33.1 -29.5 -20.3]),\n",
       " Medoid[Thread[83]=1]([-56.4 -59.9 -74.1 -77.  154.3 -30.8 -21.1 101. ]),\n",
       " Medoid[Thread[84]=1]([-141.8  -76.5  -71.9  -55.5  143.5  131.8  166.5  -31.5]),\n",
       " Medoid[Thread[85]=1]([ -70.3  -71.7  -98.8 -148.5  -20.6  129.    -4.7  159.4]),\n",
       " Medoid[Thread[86]=1]([ -74.6  -73.5  -87.  -154.2   89.6  134.   -20.2  161.3]),\n",
       " Medoid[Thread[87]=1]([-133.7  -77.2 -134.1  -59.4  113.2  119.  -177.5  157.6]),\n",
       " Medoid[Thread[88]=1]([ -90.8 -126.2 -136.4 -105.5  161.   133.7  150.   128.3]),\n",
       " Medoid[Thread[89]=1]([ -71.3 -128.7  -94.  -127.7  129.6  120.5  159.5  148.2]),\n",
       " Medoid[Thread[90]=2]([-61.5 -65.8 -62.8 -69.1 -40.8 -40.2 -41.3 -37. ]),\n",
       " Medoid[Thread[91]=1]([ -78.   -92.7  -77.4 -111.5  -19.4  -52.   -29.1  176.2])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows[0].medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0: Medoid[Thread[92]=1]([ -81.    68.6  -85.  -167.3  -35.6   45.   156.   175.3])',\n",
       " '1: Medoid[Thread[93]=1]([ -79.7   70.2 -161.2 -167.3   -7.8  -40.8  136.5  167.8])',\n",
       " '2: Medoid[Thread[94]=1]([-63.2 -65.8  57.7 -72.8 -42.4 -17.2  33.2 161.2])',\n",
       " '3: Medoid[Thread[95]=1]([-82.  -82.2 -55.2  54.5 -33.9 -15.8 133.7  23.1])',\n",
       " '4: Medoid[Thread[96]=1]([ -96.2 -141.9 -127.4 -163.8  -48.1  150.7  149.   151.5])',\n",
       " '5: Medoid[Thread[97]=1]([-108.6  -65.4  -72.6  -84.9  133.5  -29.8   -3.    -7.9])',\n",
       " '6: Medoid[Thread[98]=1]([ -89.2  -80.7 -152.9 -156.7  144.3  -31.1  142.1  155.8])',\n",
       " '7: Medoid[Thread[99]=1]([ -88.5 -110.4  -59.5  -67.9   -2.1  151.3  -29.9   -5.6])',\n",
       " '8: Medoid[Thread[82]=2]([-91.4 -97.2 -53.4 -66.  150.8 156.3 -43.6 -22.5])',\n",
       " '9: Medoid[Thread[100]=1]([-100.5 -106.3  -66.7 -126.1  141.   165.4  -22.2  123.4])',\n",
       " '10: Medoid[Thread[101]=1]([-65.3 -75.1 -92.8 -67.7 -25.7 -13.3 168.7 147.4])',\n",
       " '11: Medoid[Thread[102]=1]([-131.2 -138.   -85.7 -138.5  138.9  116.2  146.2  123.2])',\n",
       " '12: Medoid[Thread[103]=1]([-88.1 -83.6 -65.9 -75.5  79.3 150.8 132.6 151.8])',\n",
       " '13: Medoid[Thread[104]=1]([ -64.4  -73.6  -83.5 -120.3  -41.5  -44.9   76.5  127.3])',\n",
       " '14: Medoid[Thread[90]=2]([-70.6 -61.6 -68.  -72.  -42.  -44.3 -37.  -28.9])',\n",
       " '15: Medoid[Thread[76]=2]([-67.7 -58.2 -77.  -86.8 -42.  -31.1 -19.4 137.8])']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {m}' for i,m in enumerate(windows[1].medoids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = da.queries[0]\n",
    "range1 = np.concatenate([np.arange(q.winsize-1), np.arange(q.winsize, q.winsize*2-1)])\n",
    "range2 = np.concatenate([np.arange(1, q.winsize), np.arange(q.winsize+1, q.winsize*2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(diff(windows[0]._medoids[:,np.newaxis,range1], windows[1]._medoids[:,range2]), axis=2).argmin(axis=1)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
